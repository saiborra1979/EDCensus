{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "invalid-furniture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport argparse\\n\\nparser = argparse.ArgumentParser()\\nparser.add_argument('--lead', type=int, default=1, help='Which lead of the data to predict?')\\nparser.add_argument('--mdl_date', type=str, default='2020-10-01', help='Which model date to use?')\\nparser.add_argument('--groups', nargs='+',\\n                    help='Which kernel groups to include? (mds, health, demo, language, CTAS, arr, labs, DI)')\\nargs = parser.parse_args()\\nprint(args)\\nlead, mdl_date = args.lead, args.mdl_date\\ngroups = None\\nif hasattr(args, 'groups'):\\n    groups = args.groups\\n    \\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "EXAMPLE SCRIPT TO SHOW HOW TO LOAD AND RUN A GPYTORCH MODEL\n",
    "\n",
    "Assumed folder structure:\n",
    "On my HPF, the TOP_LEVEL_FOLDER == see /hpf/largeprojects/agoldenb/edrysdale/ED/\n",
    "\n",
    "TOP_LEVEL_FOLDER\n",
    "---CensusFlow\n",
    "------{all the python scripts, etc}\n",
    "---output\n",
    "------flow\n",
    "---------test\n",
    "------------{date}\n",
    "---------------*.csv [result output]\n",
    "---------------pt\n",
    "------------------[saved model weights]\n",
    "\n",
    "For example you can download the most recent output and .pt files here:\n",
    "/hpf/largeprojects/agoldenb/edrysdale/ED/output/flow/test/2021_01_11\n",
    "\n",
    "python padmanie/ex_run_mdl.py --lead 10 --mdl_date 2020-09-07 --groups mds arr CTAS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lead', type=int, default=1, help='Which lead of the data to predict?')\n",
    "parser.add_argument('--mdl_date', type=str, default='2020-10-01', help='Which model date to use?')\n",
    "parser.add_argument('--groups', nargs='+',\n",
    "                    help='Which kernel groups to include? (mds, health, demo, language, CTAS, arr, labs, DI)')\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "lead, mdl_date = args.lead, args.mdl_date\n",
    "groups = None\n",
    "if hasattr(args, 'groups'):\n",
    "    groups = args.groups\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-turning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pointed-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 10\n",
    "mdl_date = \"2020-09-07\"\n",
    "groups = ['mds', 'arr', 'CTAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "functioning-lending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from funs_support import find_dir_olu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "from mdls.gpy import mdl\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "sdev = \"cuda\" if use_cuda else \"cpu\"\n",
    "print('Using device: %s' % sdev)\n",
    "device = torch.device(sdev)\n",
    "\n",
    "# Find the top level folder (modify this function to add yours)\n",
    "dir_olu = find_dir_olu()\n",
    "print(dir_olu)\n",
    "dir_output = os.path.join(dir_olu, 'output')\n",
    "dir_flow = os.path.join(dir_output, 'flow')\n",
    "dir_test = os.path.join(dir_flow, 'test')\n",
    "lst_dir = [dir_output, dir_flow, dir_test]\n",
    "assert all([os.path.exists(path) for path in lst_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "elect-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent model rune date is: Jan 11, 2021\n"
     ]
    }
   ],
   "source": [
    "# Find the most recent date\n",
    "fn_test = pd.Series(os.listdir(dir_test))\n",
    "fn_test = fn_test[fn_test.str.contains('^[0-9]{4}')].reset_index(None,True)\n",
    "fn_test = fn_test[fn_test.str.contains('[0-9]{2}$')].reset_index(None, True)\n",
    "fn_test = pd.to_datetime(fn_test.str.replace('\\\\_', '-'))\n",
    "fn_test = fn_test[fn_test.idxmax()]\n",
    "print('Most recent model rune date is: %s' % fn_test.strftime('%b %d, %Y'))\n",
    "dir_mdl = os.path.join(dir_test, fn_test.strftime('%Y_%m_%d'))\n",
    "dir_pt = os.path.join(dir_mdl, 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polyphonic-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --- STEP 1: LOAD DATA --- #\n"
     ]
    }
   ],
   "source": [
    "print('# --- STEP 1: LOAD DATA --- #')\n",
    "idx = pd.IndexSlice\n",
    "df_lead_lags = pd.read_csv(os.path.join(dir_flow, 'df_lead_lags.csv'), header=[0, 1], index_col=[0, 1, 2, 3])\n",
    "# Create dates\n",
    "dates = df_lead_lags.index.to_frame().astype(str).assign(\n",
    "    date=lambda x: pd.to_datetime(x.year + '-' + x.month + '-' + x.day + ' ' + x.hour + ':00:00')).date\n",
    "# Extract y\n",
    "yval = df_lead_lags.loc[:, idx[:, 'lead_' + str(lead)]].values.flatten()\n",
    "# Remove lags (GP handles them automatically in the kernel)\n",
    "Xmat = df_lead_lags.loc[:, idx[:, 'lag_0']].droplevel(1, 1)\n",
    "cn = list(Xmat.columns)\n",
    "Xmat = Xmat.values\n",
    "# Extract date features (remove year/month)\n",
    "tmat = dates.index.droplevel([0, 1]).to_frame(False).reset_index().rename(columns={'index': 'trend'})\n",
    "Xmat = np.hstack([tmat.values, Xmat])\n",
    "cn = list('date_' + tmat.columns) + cn\n",
    "assert len(cn) == Xmat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "failing-tiger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --- STEP 2: LOAD MODEL --- #\n"
     ]
    }
   ],
   "source": [
    "print('# --- STEP 2: LOAD MODEL --- #')\n",
    "mdl_date = pd.to_datetime(pd.Series(mdl_date))[0]\n",
    "fn_pt = pd.Series(os.listdir(dir_pt))\n",
    "fn_pt = fn_pt[fn_pt.str.contains('lead_' + str(lead))].reset_index(None, True)\n",
    "date_pt = pd.to_datetime(fn_pt.str.split('day_', 1, True).iloc[:, 1].str.replace('.pth', ''), format='%Y%m%d')\n",
    "idx_pt = date_pt[date_pt == mdl_date].index[0]\n",
    "assert idx_pt is not None  # Ensure model date exists in that folder\n",
    "path_pt = os.path.join(dir_pt, fn_pt[idx_pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fourth-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --- STEP 3: MAKE PREDICTIONS --- #\n",
      "Test set R2: -2.365\n",
      "     y         mu         se\n",
      "0   27  16.584139   3.031407\n",
      "1   34  21.184352   4.054373\n",
      "2   43  23.281337   5.175459\n",
      "3   46  25.097243   6.351348\n",
      "4   45  25.811464   7.656909\n",
      "5   42  25.209005   8.967882\n",
      "6   40  20.263680  10.196408\n",
      "7   45  12.208421  11.339334\n",
      "8   48   6.931762  12.469951\n",
      "9   52   4.834904  13.612908\n",
      "10  56   5.693100  14.778818\n",
      "11  61   9.403973  15.917349\n",
      "12  62  17.004588  17.091307\n",
      "13  59  23.848298  18.286676\n",
      "14  52  25.428328  19.473678\n",
      "15  46  23.120354  20.630048\n",
      "16  37  23.255419  21.778945\n",
      "17  27  26.151525  22.977863\n",
      "18  26  26.175567  24.164627\n",
      "19  21  21.862673  25.322817\n",
      "20  17  17.032424  26.518695\n",
      "21  17  24.891339  27.710641\n",
      "22  14  12.964243  28.921411\n",
      "23  19   6.030648  29.847370\n"
     ]
    }
   ],
   "source": [
    "# Initialize model. Valid groups: mds, health, demo, language, CTAS, arr, labs, DI\n",
    "gp = mdl(model='gpy', lead=lead, cn=cn, device=device, groups=groups)\n",
    "# Fit the model to the data (to create X,y data to condition on for inference time)\n",
    "# I'm using the first 72 hours here\n",
    "gp.fit(X=Xmat[:72], y=yval[:72], ntrain=2, nval=1)\n",
    "gp.gp.load_state_dict(torch.load(path_pt, map_location=device), strict=True) #PMedit: added \"strict=False\" after model loading error\n",
    "\n",
    "print('# --- STEP 3: MAKE PREDICTIONS --- #')\n",
    "\n",
    "gp.gp.float()\n",
    "gp.gp.eval()\n",
    "gp.likelihood.eval()\n",
    "gp.istrained = True\n",
    "# Using the next 24 hours\n",
    "print(gp.predict(X=Xmat[72:96], y=yval[72:96]).head(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "british-alpha",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'mdl' object has no attribute 'predict_arr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a67e3ea59c4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# asking for explanation for LIME model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'mdl' object has no attribute 'predict_arr'"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(Xmat[:72],  \n",
    "mode='regression',training_labels=yval[:72],feature_names=cn)\n",
    "\n",
    "# asking for explanation for LIME model\n",
    "i = 2\n",
    "exp = explainer.explain_instance(Xmat[i,:], gp.predict_arr, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surgical-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mds', 'arr', 'CTAS']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "overall-introduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining prediction # 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'explainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-05370d9fc17b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Explaining prediction # {i}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_in_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'explainer' is not defined"
     ]
    }
   ],
   "source": [
    "# asking for explanation for LIME model\n",
    "for i in range(0,23):\n",
    "    print(f\"Explaining prediction # {i}\")\n",
    "    exp = explainer.explain_instance(Xmat[i,:], gp.predict_arr, num_features=5)\n",
    "    exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thousand-library",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-becbf8ebc64d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "Xmat.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "essential-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alien-delhi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pressed-celebrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date_trend',\n",
       " 'date_day',\n",
       " 'date_hour',\n",
       " 'census_max',\n",
       " 'census_var',\n",
       " 'tt_arrived',\n",
       " 'tt_discharged',\n",
       " 'avgmd_arrived',\n",
       " 'avgmd_discharged',\n",
       " 'u_mds10h',\n",
       " 'age_arrived',\n",
       " 'age_discharged',\n",
       " 'diastolic_arrived',\n",
       " 'diastolic_discharged',\n",
       " 'num_meds_arrived',\n",
       " 'num_meds_discharged',\n",
       " 'pulse_arrived',\n",
       " 'pulse_discharged',\n",
       " 'resp_arrived',\n",
       " 'resp_discharged',\n",
       " 'ret72_arrived',\n",
       " 'ret72_discharged',\n",
       " 'systolic_arrived',\n",
       " 'systolic_discharged',\n",
       " 'temp_arrived',\n",
       " 'temp_discharged',\n",
       " 'weight_arrived',\n",
       " 'weight_discharged',\n",
       " 'sex_F_arrived',\n",
       " 'sex_F_discharged',\n",
       " 'sex_M_arrived',\n",
       " 'sex_M_discharged',\n",
       " 'language_Amharic_arrived',\n",
       " 'language_Amharic_discharged',\n",
       " 'language_Arabic_arrived',\n",
       " 'language_Arabic_discharged',\n",
       " 'language_Bengali_arrived',\n",
       " 'language_Bengali_discharged',\n",
       " 'language_Chinese - Cantonese_arrived',\n",
       " 'language_Chinese - Cantonese_discharged',\n",
       " 'language_Chinese - Mandarin_arrived',\n",
       " 'language_Chinese - Mandarin_discharged',\n",
       " 'language_Dari_arrived',\n",
       " 'language_Dari_discharged',\n",
       " 'language_English_arrived',\n",
       " 'language_English_discharged',\n",
       " 'language_Farsi_arrived',\n",
       " 'language_Farsi_discharged',\n",
       " 'language_French_arrived',\n",
       " 'language_French_discharged',\n",
       " 'language_Hindi_arrived',\n",
       " 'language_Hindi_discharged',\n",
       " 'language_Hungarian_arrived',\n",
       " 'language_Hungarian_discharged',\n",
       " 'language_Korean_arrived',\n",
       " 'language_Korean_discharged',\n",
       " 'language_Other_arrived',\n",
       " 'language_Other_discharged',\n",
       " 'language_Portuguese_arrived',\n",
       " 'language_Portuguese_discharged',\n",
       " 'language_Punjabi_arrived',\n",
       " 'language_Punjabi_discharged',\n",
       " 'language_Russian_arrived',\n",
       " 'language_Russian_discharged',\n",
       " 'language_Slovak_arrived',\n",
       " 'language_Slovak_discharged',\n",
       " 'language_Somali_arrived',\n",
       " 'language_Somali_discharged',\n",
       " 'language_Spanish_arrived',\n",
       " 'language_Spanish_discharged',\n",
       " 'language_Tagalog_arrived',\n",
       " 'language_Tagalog_discharged',\n",
       " 'language_Tamil_arrived',\n",
       " 'language_Tamil_discharged',\n",
       " 'language_Tigrinya_arrived',\n",
       " 'language_Tigrinya_discharged',\n",
       " 'language_Turkish_arrived',\n",
       " 'language_Turkish_discharged',\n",
       " 'language_Urdu_arrived',\n",
       " 'language_Urdu_discharged',\n",
       " 'language_Vietnamese_arrived',\n",
       " 'language_Vietnamese_discharged',\n",
       " 'language_missing_arrived',\n",
       " 'language_missing_discharged',\n",
       " 'CTAS_1.0_arrived',\n",
       " 'CTAS_1.0_discharged',\n",
       " 'CTAS_2.0_arrived',\n",
       " 'CTAS_2.0_discharged',\n",
       " 'CTAS_3.0_arrived',\n",
       " 'CTAS_3.0_discharged',\n",
       " 'CTAS_4.0_arrived',\n",
       " 'CTAS_4.0_discharged',\n",
       " 'CTAS_5.0_arrived',\n",
       " 'CTAS_5.0_discharged',\n",
       " 'CTAS_missing_arrived',\n",
       " 'CTAS_missing_discharged',\n",
       " 'arr_method_Air & Ground Ambulance_arrived',\n",
       " 'arr_method_Air & Ground Ambulance_discharged',\n",
       " 'arr_method_Air Ambulance_arrived',\n",
       " 'arr_method_Air Ambulance_discharged',\n",
       " 'arr_method_Ambulatory_arrived',\n",
       " 'arr_method_Ambulatory_discharged',\n",
       " 'arr_method_Bus_arrived',\n",
       " 'arr_method_Bus_discharged',\n",
       " 'arr_method_Car_arrived',\n",
       " 'arr_method_Car_discharged',\n",
       " 'arr_method_Helicopter_arrived',\n",
       " 'arr_method_Helicopter_discharged',\n",
       " 'arr_method_Land Ambulance_arrived',\n",
       " 'arr_method_Land Ambulance_discharged',\n",
       " 'arr_method_Other_arrived',\n",
       " 'arr_method_Other_discharged',\n",
       " 'arr_method_Police_arrived',\n",
       " 'arr_method_Police_discharged',\n",
       " 'arr_method_Stretcher_arrived',\n",
       " 'arr_method_Stretcher_discharged',\n",
       " 'arr_method_Taxi_arrived',\n",
       " 'arr_method_Taxi_discharged',\n",
       " 'arr_method_Transfer In_arrived',\n",
       " 'arr_method_Transfer In_discharged',\n",
       " 'arr_method_Unknown_arrived',\n",
       " 'arr_method_Unknown_discharged',\n",
       " 'arr_method_Walk_arrived',\n",
       " 'arr_method_Walk_discharged',\n",
       " 'arr_method_missing_arrived',\n",
       " 'arr_method_missing_discharged',\n",
       " 'DistSK_1_2_arrived',\n",
       " 'DistSK_1_2_discharged',\n",
       " 'DistSK_2_3_arrived',\n",
       " 'DistSK_2_3_discharged',\n",
       " 'DistSK_3_4_arrived',\n",
       " 'DistSK_3_4_discharged',\n",
       " 'DistSK_4+_arrived',\n",
       " 'DistSK_4+_discharged',\n",
       " 'DistSK_<1_arrived',\n",
       " 'DistSK_<1_discharged',\n",
       " 'DistSK_missing_arrived',\n",
       " 'DistSK_missing_discharged',\n",
       " 'labs_albumin',\n",
       " 'labs_alt',\n",
       " 'labs_ast',\n",
       " 'labs_bilirubin',\n",
       " 'labs_blood',\n",
       " 'labs_c-reactive',\n",
       " 'labs_cbc',\n",
       " 'labs_creatinine',\n",
       " 'labs_differential',\n",
       " 'labs_esr',\n",
       " 'labs_glucose',\n",
       " 'labs_other',\n",
       " 'labs_peripheral',\n",
       " 'labs_potassium',\n",
       " 'labs_rapid',\n",
       " 'labs_sodium',\n",
       " 'labs_throat',\n",
       " 'labs_urinalysis',\n",
       " 'labs_urine',\n",
       " 'DI_ai',\n",
       " 'DI_ct',\n",
       " 'DI_gi',\n",
       " 'DI_mri',\n",
       " 'DI_other',\n",
       " 'DI_us',\n",
       " 'DI_xray']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-aquarium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
